{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nandhureji1731/springboardmentor5959e/blob/main/oil_spill__detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giNAJpNdOQHo"
      },
      "source": [
        "WEEK 1-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "64G4QKexbvVD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c02a5ff5-a0be-4fea-e3de-9b79f457afcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "âœ… Project folder ready at: /content/drive/MyDrive/Oil_Spill_Detection\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import os\n",
        "PROJECT_DIR = \"/content/drive/MyDrive/Oil_Spill_Detection\"\n",
        "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
        "print(\"âœ… Project folder ready at:\", PROJECT_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lkyoH674oLSC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54560ee9-ae9f-44d6-fb24-75ea5a4bd4fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path where dataset is stored inside Drive\n",
        "BASE_PATH = \"/content/drive/MyDrive/dataset/\"\n",
        "TRAIN_IMG_DIR = BASE_PATH + \"train/images/\"\n",
        "TRAIN_MASK_DIR = BASE_PATH + \"train/masks/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NtzlBWJuohcO"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import albumentations as A\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfgFbhHQopEx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08caa2e3-1486-4833-9dc2-189698c2db7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of image directory /content/drive/MyDrive/dataset/train/images/: ['Oil (225).jpg', 'Oil (652).jpg', 'Oil (72).jpg', 'Oil (1157).jpg', 'Oil (122).jpg', 'Oil (107).jpg', 'Oil (450).jpg', 'Oil (1054).jpg', 'Oil (297).jpg', 'Oil (523).jpg']...\n",
            "Contents of mask directory /content/drive/MyDrive/dataset/train/masks/: ['Oil (503).png', 'Oil (676).png', 'Oil (551).png', 'Oil (652).png', 'Oil (989).png', 'Oil (481).png', 'Oil (163).png', 'Oil (73).png', 'Oil (1054).png', 'Oil (830).png']...\n"
          ]
        }
      ],
      "source": [
        "def load_data(img_dir, mask_dir, img_size=(256, 256)):\n",
        "    images, masks = [], []\n",
        "\n",
        "\n",
        "    if not os.path.exists(img_dir):\n",
        "        print(f\"Error: Image directory not found: {img_dir}\")\n",
        "        return None, None\n",
        "    if not os.path.exists(mask_dir):\n",
        "        print(f\"Error: Mask directory not found: {mask_dir}\")\n",
        "        return None, None\n",
        "\n",
        "    print(f\"Contents of image directory {img_dir}: {os.listdir(img_dir)[:10]}...\") # Print first 10 files\n",
        "    print(f\"Contents of mask directory {mask_dir}: {os.listdir(mask_dir)[:10]}...\") # Print first 10 files\n",
        "\n",
        "\n",
        "    img_files = sorted(os.listdir(img_dir))\n",
        "    mask_files = sorted(os.listdir(mask_dir))\n",
        "\n",
        "    if len(img_files) != len(mask_files):\n",
        "        print(f\"Warning: Number of image files ({len(img_files)}) does not match number of mask files ({len(mask_files)}).\")\n",
        "\n",
        "\n",
        "    for img_name, mask_name in zip(img_files, mask_files):\n",
        "        img_path = os.path.join(img_dir, img_name)\n",
        "        mask_path = os.path.join(mask_dir, mask_name)\n",
        "\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            print(f\"Warning: Could not load image file: {img_path}. Skipping.\")\n",
        "            continue\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, img_size)\n",
        "        img = img / 255.0\n",
        "\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if mask is None:\n",
        "            print(f\"Warning: Could not load mask file: {mask_path}. Skipping.\")\n",
        "            continue\n",
        "        mask = cv2.resize(mask, img_size)\n",
        "        mask = mask / 255.0\n",
        "\n",
        "        images.append(img)\n",
        "        masks.append(mask.reshape(img_size[0], img_size[1], 1))\n",
        "\n",
        "    return np.array(images), np.array(masks)\n",
        "\n",
        "X, Y = load_data(TRAIN_IMG_DIR, TRAIN_MASK_DIR)\n",
        "\n",
        "if X is not None and Y is not None:\n",
        "    print(\"Images shape:\", X.shape)\n",
        "    print(\"Masks shape:\", Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRhFenxPorOX"
      },
      "outputs": [],
      "source": [
        "def visualize_samples(X, Y, num_samples=3):\n",
        "    if X is None or Y is None:\n",
        "        print(\"Cannot visualize samples: Data not loaded properly.\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(10, num_samples * 3))\n",
        "    for i in range(num_samples):\n",
        "        idx = np.random.randint(0, len(X))\n",
        "        plt.subplot(num_samples, 2, 2*i+1)\n",
        "        plt.imshow(X[idx])\n",
        "        plt.title(\"Image\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.subplot(num_samples, 2, 2*i+2)\n",
        "        plt.imshow(Y[idx].squeeze(), cmap=\"gray\")\n",
        "        plt.title(\"Mask\")\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "visualize_samples(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eb9Hz8DMoucv"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training set:\", X_train.shape, Y_train.shape)\n",
        "print(\"Validation set:\", X_val.shape, Y_val.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgGZaL_iowku"
      },
      "outputs": [],
      "source": [
        "augment = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.RandomRotate90(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.2)\n",
        "])\n",
        "\n",
        "def augment_data(image, mask):\n",
        "    augmented = augment(image=(image*255).astype(np.uint8), mask=(mask*255).astype(np.uint8))\n",
        "    return augmented['image']/255.0, augmented['mask']/255.0\n",
        "\n",
        "#Eg\n",
        "aug_img, aug_mask = augment_data(X[0], Y[0])\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(aug_img)\n",
        "plt.title(\"Augmented Image\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(aug_mask, cmap=\"gray\")\n",
        "plt.title(\"Augmented Mask\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ps66ueYOLcN"
      },
      "source": [
        "WEEK 3-4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWFcrJ1231ir"
      },
      "source": [
        "import\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aB4dGBZs6pDh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLAj2P1d35o2"
      },
      "source": [
        "\n",
        " model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czHCIUkt6rlu"
      },
      "outputs": [],
      "source": [
        "\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = tf.keras.backend.flatten(y_true)\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
        "\n",
        "def conv_block(x, filters):\n",
        "    x = layers.Conv2D(filters, (3,3), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.Conv2D(filters, (3,3), padding=\"same\", activation=\"relu\")(x)\n",
        "    return x\n",
        "\n",
        "def encoder_block(x, filters):\n",
        "    c = conv_block(x, filters)\n",
        "    p = layers.MaxPooling2D((2,2))(c)\n",
        "    return c, p\n",
        "\n",
        "def decoder_block(x, skip, filters):\n",
        "    us = layers.Conv2DTranspose(filters, (2,2), strides=(2,2), padding=\"same\")(x)\n",
        "    concat = layers.Concatenate()([us, skip])\n",
        "    c = conv_block(concat, filters)\n",
        "    return c\n",
        "\n",
        "def build_unet(input_shape=(128,128,3)):\n",
        "    inputs = layers.Input(input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    c1, p1 = encoder_block(inputs, 32)\n",
        "    c2, p2 = encoder_block(p1, 64)\n",
        "    c3, p3 = encoder_block(p2, 128)\n",
        "\n",
        "    # Bottleneck\n",
        "    bn = conv_block(p3, 256)\n",
        "\n",
        "    # Decoder\n",
        "    d1 = decoder_block(bn, c3, 128)\n",
        "    d2 = decoder_block(d1, c2, 64)\n",
        "    d3 = decoder_block(d2, c1, 32)\n",
        "\n",
        "    outputs = layers.Conv2D(1, (1,1), activation=\"sigmoid\")(d3)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Build model\n",
        "model = build_unet()\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\", dice_coef])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAEfSXin6xnc"
      },
      "source": [
        "resize for faster execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqWa3wAT618J"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = (128,128)  # faster than 256x256\n",
        "\n",
        "X_small, Y_small = load_data(TRAIN_IMG_DIR, TRAIN_MASK_DIR, img_size=IMG_SIZE)\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_small, Y_small, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Train:\", X_train.shape, \"Val:\", X_val.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS2E4Ghz65jf"
      },
      "source": [
        "metrics and compile model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdmUlVgu6-lU"
      },
      "outputs": [],
      "source": [
        "def iou_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = tf.keras.backend.flatten(y_true)\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    union = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) - intersection\n",
        "    return (intersection + smooth) / (union + smooth)\n",
        "\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[ \"accuracy\",dice_coef])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6aRC_2o7Bl1"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLQlDMaq7EN-"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    X_train, Y_train,\n",
        "    validation_data=(X_val, Y_val),\n",
        "    batch_size=8,\n",
        "    epochs=25,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-ZbxHgY7Ia6"
      },
      "source": [
        "Visual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zZAZy8hj-Nr"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "if 'accuracy' in history.history:\n",
        "  plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
        "if 'val_accuracy' in history.history:\n",
        "  plt.plot(history.history[\"val_accuracy\"], label=\"Val Accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Accuracy\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5HtVGn-7Jyv"
      },
      "outputs": [],
      "source": [
        "def show_predictions(model, X, Y, num=3):\n",
        "    preds = model.predict(X[:num])\n",
        "    plt.figure(figsize=(10, num*3))\n",
        "    for i in range(num):\n",
        "        plt.subplot(num,3,3*i+1)\n",
        "        plt.imshow(X[i])\n",
        "        plt.title(\"Image\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.subplot(num,3,3*i+2)\n",
        "        plt.imshow(Y[i].squeeze(), cmap=\"gray\")\n",
        "        plt.title(\"Mask\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.subplot(num,3,3*i+3)\n",
        "        plt.imshow((preds[i].squeeze() > 0.5), cmap=\"gray\")\n",
        "        plt.title(\"Prediction\")\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "show_predictions(model, X_val, Y_val, num=3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJrzt_t6FdSt"
      },
      "source": [
        "week 5-6\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEx7387ZFfac"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras.backend as K\n",
        "\n",
        "def iou_metric(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth)\n",
        "\n",
        "def precision_metric(y_true, y_pred):\n",
        "    y_pred_f = K.round(K.flatten(y_pred))\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    tp = K.sum(y_true_f * y_pred_f)\n",
        "    fp = K.sum((1 - y_true_f) * y_pred_f)\n",
        "    return tp / (tp + fp + K.epsilon())\n",
        "\n",
        "def recall_metric(y_true, y_pred):\n",
        "    y_pred_f = K.round(K.flatten(y_pred))\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    tp = K.sum(y_true_f * y_pred_f)\n",
        "    fn = K.sum(y_true_f * (1 - y_pred_f))\n",
        "    return tp / (tp + fn + K.epsilon())\n",
        "\n",
        "# Recompile model with full metrics\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\", dice_coef, iou_metric, precision_metric, recall_metric])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fMoqEG_FjYJ"
      },
      "source": [
        "evaluation on valid set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvQskkanFjAN"
      },
      "outputs": [],
      "source": [
        "results = model.evaluate(X_val, Y_val, verbose=1)\n",
        "print(\"Validation Results:\")\n",
        "for name, val in zip(model.metrics_names, results):\n",
        "    print(f\"{name}: {val:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQj0K3DwFqUt"
      },
      "source": [
        "plot training curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8g_LKsChFs2M"
      },
      "outputs": [],
      "source": [
        "def plot_training(history):\n",
        "    plt.figure(figsize=(12,5))\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
        "    plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
        "    plt.title(\"Loss Curve\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Dice Coefficient\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history[\"dice_coef\"], label=\"Train Dice\")\n",
        "    plt.plot(history.history[\"val_dice_coef\"], label=\"Val Dice\")\n",
        "    plt.title(\"Dice Coefficient\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Dice\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_training(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6VrDmw5Fv_H"
      },
      "source": [
        "side by side visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22bXAhqhFzc4"
      },
      "outputs": [],
      "source": [
        "def compare_predictions(model, X, Y, num=3):\n",
        "    preds = model.predict(X[:num])\n",
        "    plt.figure(figsize=(10, num*3))\n",
        "    for i in range(num):\n",
        "        plt.subplot(num,3,3*i+1)\n",
        "        plt.imshow(X[i])\n",
        "        plt.title(\"Image\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.subplot(num,3,3*i+2)\n",
        "        plt.imshow(Y[i].squeeze(), cmap=\"gray\")\n",
        "        plt.title(\"Ground Truth\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.subplot(num,3,3*i+3)\n",
        "        plt.imshow((preds[i].squeeze() > 0.5), cmap=\"gray\")\n",
        "        plt.title(\"Prediction\")\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "compare_predictions(model, X_val, Y_val, num=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrdOJSozbGek"
      },
      "source": [
        "week 7-8\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp \"/content/drive/MyDrive/Oil_Spill_Detection/oil_spill_unet.h5\" ./oil_spill_unet.h5\n"
      ],
      "metadata": {
        "id": "Hu3KmmcDPvD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6BBC2yDa3DNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "vTp9e167E86l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "id": "J9LwCQQRE_qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "# Set the auth token\n",
        "ngrok.conf.get_default().auth_token = \"33QYdWt6Mb7yKPlc8cRs6QTJHk2_7Gz7L9Uw6WGT6TU5wGakq\"\n",
        "print(\"âœ… Auth token set successfully.\")"
      ],
      "metadata": {
        "id": "4-MY5TWp3FPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "flask backend"
      ],
      "metadata": {
        "id": "F-XOm31dfg0M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "streamlet"
      ],
      "metadata": {
        "id": "LVbwoeImfpGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "from pathlib import Path\n",
        "from typing import Tuple\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps\n",
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Oil_Spill_Detection/oil_spill_unet.h5\"  #train model present\n",
        "RESULTS_DIR = \"results\"\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "USERNAME = \"admin\"\n",
        "PASSWORD = \"oilspill2025\"\n",
        "\n",
        "# Helpers\n",
        "\n",
        "@st.cache_resource\n",
        "def load_seg_model(path: str):\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"Model file not found at: {path}\")\n",
        "    model = load_model(path, compile=False)\n",
        "    return model\n",
        "\n",
        "def get_input_size_from_model(model) -> Tuple[int, int]:\n",
        "    shape = model.input_shape\n",
        "    if isinstance(shape, list):\n",
        "        shape = shape[0]\n",
        "    _, h, w, c = shape\n",
        "    return (h, w)\n",
        "\n",
        "def preprocess_image(img: Image.Image, target_size: Tuple[int, int]):\n",
        "    img = img.convert(\"RGB\")\n",
        "    img = ImageOps.fit(img, target_size, Image.LANCZOS)\n",
        "    arr = np.asarray(img) / 255.0\n",
        "    return arr\n",
        "\n",
        "def postprocess_mask(mask: np.ndarray, orig_size: Tuple[int, int]):\n",
        "    m = mask.squeeze()\n",
        "    m = (m - m.min()) / (m.max() - m.min() + 1e-8)\n",
        "    m = (m * 255).astype(np.uint8)\n",
        "    mask_img = Image.fromarray(m).resize(orig_size, Image.BILINEAR)\n",
        "    return mask_img\n",
        "\n",
        "def overlay_mask_on_image(image: Image.Image, mask_img: Image.Image, alpha=0.45):\n",
        "    mask_colored = Image.new(\"RGBA\", image.size)\n",
        "    r, g, b, a = mask_colored.split()\n",
        "    mask_arr = np.asarray(mask_img.convert(\"L\"))\n",
        "    rgba = np.zeros((image.size[1], image.size[0], 4), dtype=np.uint8)\n",
        "    rgba[..., 0] = mask_arr  # red\n",
        "    rgba[..., 3] = (mask_arr * alpha).astype(np.uint8)\n",
        "    mask_overlay = Image.fromarray(rgba, mode=\"RGBA\")\n",
        "    base = image.convert(\"RGBA\")\n",
        "    combined = Image.alpha_composite(base, mask_overlay)\n",
        "    return combined.convert(\"RGB\")\n",
        "\n",
        "def save_result(original: Image.Image, mask_img: Image.Image, overlay: Image.Image, prefix=\"result\"):\n",
        "    t = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    base_name = f\"{prefix}_{t}\"\n",
        "    orig_path = os.path.join(RESULTS_DIR, f\"{base_name}_orig.png\")\n",
        "    mask_path = os.path.join(RESULTS_DIR, f\"{base_name}_mask.png\")\n",
        "    overlay_path = os.path.join(RESULTS_DIR, f\"{base_name}_overlay.png\")\n",
        "    original.save(orig_path)\n",
        "    mask_img.save(mask_path)\n",
        "    overlay.save(overlay_path)\n",
        "    return orig_path, mask_path, overlay_path\n",
        "\n",
        "\n",
        "# Login Page\n",
        "\n",
        "def show_login_page():\n",
        "    st.title(\"ðŸ›Ÿ AI SpillGuard â€” Login\")\n",
        "    st.markdown(\"### Please log in to access the Oil Spill Detection tool\")\n",
        "\n",
        "    with st.form(key=\"login_form\"):\n",
        "        username = st.text_input(\"ðŸ‘¤ Username\")\n",
        "        password = st.text_input(\"ðŸ”’ Password\", type=\"password\")\n",
        "        col1, col2, col3 = st.columns([1, 1, 1])\n",
        "        with col2:\n",
        "            submit = st.form_submit_button(\"ðŸš€ Login\", use_container_width=True)\n",
        "\n",
        "        if submit:\n",
        "            if username == USERNAME and password == PASSWORD:\n",
        "                st.session_state[\"logged_in\"] = True\n",
        "                st.session_state[\"username\"] = username\n",
        "                st.success(\"âœ… Login successful! Redirecting...\")\n",
        "                st.rerun()  # Updated to use st.rerun()\n",
        "            else:\n",
        "                st.error(\"âŒ Invalid username or password. Please try again.\")\n",
        "                st.info(f\"Default credentials: Username: {USERNAME}, Password: {PASSWORD}\")\n",
        "\n",
        "\n",
        "# Main App\n",
        "\n",
        "def show_main_app():\n",
        "    # Header\n",
        "    st.title(\"ðŸ›Ÿ AI SpillGuard â€” Oil Spill Detection\")\n",
        "    st.markdown(\"**Welcome, {}!**\".format(st.session_state.get(\"username\", \"User\")))\n",
        "\n",
        "    st.set_page_config(\n",
        "        page_title=\"AI SpillGuard â€” Oil Spill Detection\",\n",
        "        page_icon=\"ðŸ›Ÿ\",\n",
        "        layout=\"wide\",\n",
        "        initial_sidebar_state=\"expanded\",\n",
        "    )\n",
        "\n",
        "    # Sidebar: controls & info\n",
        "    st.sidebar.title(\"âš™ï¸ Controls\")\n",
        "    st.sidebar.markdown(\"**Oil spill segmentation from satellite imagery**\")\n",
        "    st.sidebar.markdown(\"---\")\n",
        "    st.sidebar.write(\"**ðŸ¤– Model:**\")\n",
        "    st.sidebar.write(MODEL_PATH)\n",
        "    st.sidebar.markdown(\"---\")\n",
        "    show_examples = st.sidebar.checkbox(\"ðŸ–¼ï¸ Show example images\", value=True)\n",
        "    download_history = st.sidebar.checkbox(\"ðŸ’¾ Enable result download buttons\", value=True)\n",
        "    st.sidebar.markdown(\"---\")\n",
        "    if st.sidebar.button(\"ðŸšª Logout\"):\n",
        "        for key in list(st.session_state.keys()):\n",
        "            del st.session_state[key]\n",
        "        st.rerun()  # Updated to use st.rerun()\n",
        "    st.sidebar.markdown(\"---\")\n",
        "    st.sidebar.caption(\"ðŸ‘¨â€ðŸ’» Developed by Nandhu Reji\")\n",
        "\n",
        "    # Main content\n",
        "    col1, col2 = st.columns([1, 1.2])\n",
        "\n",
        "    with col1:\n",
        "        st.header(\"ðŸ“¤ Upload Satellite Image\")\n",
        "        uploaded = st.file_uploader(\n",
        "            \"Drop an image or choose from device\",\n",
        "            type=[\"png\", \"jpg\", \"jpeg\", \"tif\", \"tiff\"],\n",
        "            help=\"Upload satellite imagery for oil spill detection\"\n",
        "        )\n",
        "        st.markdown(\"**ðŸ’¡ Tip:** For consistent results, use images similar to your training data (SAR or RGB).\")\n",
        "        st.write(\"\")\n",
        "\n",
        "        if uploaded:\n",
        "            img = Image.open(io.BytesIO(uploaded.read()))\n",
        "            st.image(img, caption=\"Uploaded image (preview)\", use_column_width=True)\n",
        "            run_predict = st.button(\"ðŸ” Run Prediction\", use_container_width=True)\n",
        "        else:\n",
        "            run_predict = False\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.subheader(\"âš™ï¸ Quick settings\")\n",
        "        alpha = st.slider(\"ðŸŽ¨ Overlay alpha (opacity)\", min_value=0.05, max_value=1.0, value=0.45)\n",
        "        bin_threshold = st.slider(\"ðŸŽ¯ Mask threshold (0-255)\", 0, 255, 127)\n",
        "\n",
        "    with col2:\n",
        "        st.header(\"ðŸ“Š Prediction results\")\n",
        "        placeholder = st.empty()\n",
        "        if not uploaded:\n",
        "            placeholder.info(\"ðŸ‘ˆ Upload an image on the left and click **Run Prediction** to see segmentation results.\")\n",
        "        else:\n",
        "            placeholder.success(\"âœ… Ready to predict â€” click **Run Prediction**\")\n",
        "\n",
        "    # Show examples if enabled\n",
        "    if show_examples:\n",
        "        st.markdown(\"### ðŸ–¼ï¸ Example dataset images\")\n",
        "        example_cols = st.columns(4)\n",
        "        ex_dir = Path(\"examples\")\n",
        "        if ex_dir.exists():\n",
        "            ex_images = sorted([p for p in ex_dir.glob(\"*\")][:4])\n",
        "            for i, p in enumerate(ex_images):\n",
        "                with example_cols[i]:\n",
        "                    st.image(str(p), use_column_width=True, caption=p.name)\n",
        "        else:\n",
        "            st.warning(\"No example images found in `examples/`. You can add sample images there for demo.\")\n",
        "\n",
        "    # Prediction logic\n",
        "    if run_predict and uploaded:\n",
        "        try:\n",
        "            with st.spinner(\"ðŸ”„ Loading model...\"):\n",
        "                model = load_seg_model(MODEL_PATH)\n",
        "            input_h, input_w = get_input_size_from_model(model)\n",
        "        except Exception as e:\n",
        "            st.error(f\"âŒ Could not load model: {e}\")\n",
        "            st.stop()\n",
        "\n",
        "        orig_size = (img.width, img.height)\n",
        "        target_size = (input_w, input_h)\n",
        "        arr = preprocess_image(img, target_size)\n",
        "        x = np.expand_dims(arr, axis=0).astype(np.float32)\n",
        "\n",
        "        with st.spinner(\"ðŸ§  Running inference...\"):\n",
        "            pred = model.predict(x, verbose=0)\n",
        "        mask_raw = pred[0]\n",
        "        if mask_raw.max() > 1.01:\n",
        "            mask_raw = 1.0 / (1.0 + np.exp(-mask_raw))\n",
        "        mask_img = postprocess_mask(mask_raw, orig_size)\n",
        "        mask_bin = mask_img.point(lambda p: 255 if p >= bin_threshold else 0)\n",
        "        overlay = overlay_mask_on_image(img, mask_bin, alpha=alpha)\n",
        "\n",
        "        # Results display\n",
        "        st.markdown(\"---\")\n",
        "        st.subheader(\"ðŸŽ¯ Detection Results\")\n",
        "        rcol1, rcol2, rcol3 = st.columns([1, 1, 1])\n",
        "        with rcol1:\n",
        "            st.subheader(\"ðŸ“· Original\")\n",
        "            st.image(img, use_column_width=True)\n",
        "        with rcol2:\n",
        "            st.subheader(\"ðŸŽ­ Predicted Mask\")\n",
        "            st.image(mask_bin.convert(\"L\"), use_column_width=True)\n",
        "        with rcol3:\n",
        "            st.subheader(\"ðŸ”´ Overlay\")\n",
        "            st.image(overlay, use_column_width=True)\n",
        "\n",
        "        # Save and download\n",
        "        orig_path, mask_path, overlay_path = save_result(img, mask_bin, overlay, prefix=\"spill\")\n",
        "        st.success(\"âœ… Prediction complete â€” results saved to the workspace.\")\n",
        "\n",
        "        if download_history:\n",
        "            st.markdown(\"### ðŸ’¾ Download Results\")\n",
        "            col_d1, col_d2, col_d3 = st.columns(3)\n",
        "            with col_d1:\n",
        "                with open(overlay_path, \"rb\") as f:\n",
        "                    st.download_button(\n",
        "                        label=\"Overlay\",\n",
        "                        data=f.read(),\n",
        "                        file_name=os.path.basename(overlay_path),\n",
        "                        mime=\"image/png\"\n",
        "                    )\n",
        "            with col_d2:\n",
        "                with open(mask_path, \"rb\") as f:\n",
        "                    st.download_button(\n",
        "                        label=\"Mask\",\n",
        "                        data=f.read(),\n",
        "                        file_name=os.path.basename(mask_path),\n",
        "                        mime=\"image/png\"\n",
        "                    )\n",
        "            with col_d3:\n",
        "                with open(orig_path, \"rb\") as f:\n",
        "                    st.download_button(\n",
        "                        label=\"Original\",\n",
        "                        data=f.read(),\n",
        "                        file_name=os.path.basename(orig_path),\n",
        "                        mime=\"image/png\"\n",
        "                    )\n",
        "\n",
        "        # Summary metrics\n",
        "        mask_np = np.asarray(mask_bin.convert(\"L\"))\n",
        "        area_pct = 100.0 * (np.count_nonzero(mask_np) / mask_np.size)\n",
        "        col1, col2 = st.columns(2)\n",
        "        with col1:\n",
        "            st.metric(\"ðŸ“ Estimated spill area (%)\", f\"{area_pct:.3f}%\")\n",
        "        with col2:\n",
        "            st.metric(\"ðŸ• Processing time\", \"Fast\")\n",
        "\n",
        "        st.markdown(\"### ðŸ“ Saved files:\")\n",
        "        st.code(f\"- {orig_path}\\n- {mask_path}\\n- {overlay_path}\")\n",
        "\n",
        "    # Footer\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"### ðŸ‘¨â€ðŸ’» Developed by Nandhu Reji\")\n",
        "    st.caption(\"*If model file missing, upload `oil_spill_unet.h5` into the Colab working directory, or change MODEL_PATH in app.py*\")\n",
        "\n",
        "#login\n",
        "if \"logged_in\" not in st.session_state:\n",
        "    st.session_state[\"logged_in\"] = False\n",
        "\n",
        "if not st.session_state[\"logged_in\"]:\n",
        "    show_login_page()\n",
        "else:\n",
        "    show_main_app()"
      ],
      "metadata": {
        "id": "5Hcq0xyjV1oT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyngrok import ngrok\n",
        "import subprocess, time, os\n",
        "\n",
        "# kill any existing tunnels\n",
        "for t in ngrok.get_tunnels():\n",
        "    ngrok.disconnect(t.public_url)\n",
        "\n",
        "# start streamlit in background\n",
        "port = 8501\n",
        "cmd = f\"streamlit run app.py --server.port {port} --server.headless true\"\n",
        "proc = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "time.sleep(3)\n",
        "\n",
        "public_url = ngrok.connect(port, \"http\")\n",
        "print(\">> Streamlit public URL:\", public_url)\n",
        "print(\"If the page doesn't load immediately, wait ~5-15s and refresh.\")\n"
      ],
      "metadata": {
        "id": "hW04oW8hV83L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py"
      ],
      "metadata": {
        "id": "bdzurTSDV_-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh\n"
      ],
      "metadata": {
        "id": "_FK9F7YzW59s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tailwind\n"
      ],
      "metadata": {
        "id": "Fj172dnNnvRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%bash\n",
        "pip install flask==2.2.5 flask-cors pillow numpy pyngrok==5.2.1 tensorflow==2.12.0 >/dev/null 2>&1 || true\n",
        "\n",
        "mkdir -p /content/spillguard_app/static\n",
        "mkdir -p /content/spillguard_app/static/assets\n",
        "mkdir -p /content/spillguard_app/results\n"
      ],
      "metadata": {
        "id": "LUn0hgC0nxX2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMG0yH1Zn1thDH9fI74hxZO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}